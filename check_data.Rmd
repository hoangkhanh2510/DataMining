---
title: "DM1"
author: "Cong Bang Huynh"
date: "12/11/2020"
output: word_document
---


```{r}
install.packages("devtools")
library(devtools)
devtools::install_github("clepadellec/ClustersAnalysis")
install.packages("readr")
```


```{r}
library(e1071)
library(Metrics)
library(caret)
library(openxlsx)
library(ClustersAnalysis)
library(rpart) #arbre de decision
library(rpart.plot)
library(ROCR)  # tracer la courbe de Roc
library(Metrics) # calculer aire sous la courbe de Roc
library(gbm) # gradient boosting

```




```{r}
library(openxlsx)
library(ClustersAnalysis)
library(tidyverse)
```

```{r}
setwd("/Users/hoangkhanhle/Desktop/School/Master 2/Data Mining/Projet/")
df=read.csv("Train_data.csv")
```



```{r}
head(df,10)
```



```{r}
df_not_class=df[,-42]
head(df_not_class)
```

###### variable qualitative #########


```{r}
var_quanti=sapply(df_not_class, function(x) is.factor(x)| is.character(x)|length(unique(x))<50)

```

```{r}
var=var_quanti==FALSE
```



```{r}
df_not_class_quanti=df_not_class[,var]
```


```{r}
head(df_not_class_quanti,10)
```

```{r}
data=cbind(df_not_class_quanti,df$class)
```


```{r}
head(data,10)
```

######################## Test ###########################################################


```{r}
object=multivariate_object(data,22)
```

```{r}
m_test.value(object = object,i=1)
```
```{r}
help(m_test.value)
```

#les variables hot/dst_bytes/src_bytes/srv_count caracterise la classe 'normal' le plus mauvais


```{r}
x=m_test.value(object = object,i=2)

```
```{r}
x$pvalue<=0.05
```

# les variables hot/dst_bytes/src_bytes/srv_count caracterise la classe 'normal' le plus mauvais:

```{r}
data_final=data[,-c(2,3,5)]
```

```{r}
object=multivariate_object(data_final,19)
```



# Rapport de correlation

```{r}
### R^2

m_R2_multivariate(object, rescale = TRUE)


```





```{r}
colnames(data_final)
```


# fisher test


```{r}
u_object=Univariate_object(data_final,19)
```



```{r}
u_fisher_test_all(u_object)
```






# Le nombre des valeurs differentes pour chaque colonne

```{r}
for (i in 1:18){
  a=length(unique(data_final[,i]))
  print(paste(colnames(data_final[i]), a))
}
```

##Séparer en train-test (0.75-0.25)

```{r}
colnames(data_final)[19]='class'
```


```{r}
n=nrow(data_final)
ind_test=sample(1:n, n*0.25, replace = FALSE, prob = NULL)
data_train=data_final[-ind_test,]
data_test=data_final[ind_test,]
```








###################ACP########################################################################################




```{r}
#ACP + clustering sur l'apprentissage (data_train)
m_data_train=multivariate_object(data_train,19)
m_kmean_clustering_plot(m_data_train, interact = FALSE, rescale = TRUE)
```



```{r}
#ACP + clustering sur le test (data_test)
m_data_test=multivariate_object(data_test,19)
m_kmean_clustering_plot(m_data_train, interact = FALSE)
```



```{r}
#ACP + clustering sur le test (data_test)
m_data_total=multivariate_object(data_final,19)
m_kmean_clustering_plot(m_data_total, interact = FALSE, i=1,j=2)

```
















#################### TEST AVEC ARBRE DE DECISION (PAS ENCORE CV) ################################################
#TEST AVEC ARBRE DE DECISION
#################################################################################################################
########################################### ARBRE DE DECISION ###################################################
#################################################################################################################


```{r}
head(data_train)
```





##Lancer Arbre de decision

```{r}
library(rpart)
data_train_arbre=rpart(class~.,data=data_train, method = "class")
plot(data_train_arbre)
text(data_train_arbre)

```

```{r}
library(rpart.plot)

rpart.plot(data_train_arbre)
```

## Predire avec arbre de decision



```{r}
predict=predict(data_train_arbre, data_test,"class")
```


## Calculer les metriques

```{r}
# Matrice de confusion

conf1=table(data_test$class,predict)
print(conf1)

# Taux d'erreur

print(1-sum(diag(conf1))/sum(conf1))

# Taux rappel

print(conf1[2,2]/sum(conf1["normal",]))

# Taux precision

print(conf1[2,2]/sum(conf1[,"normal"]))
```


## tuning les hyperparametres

```{r}
para=rpart.control(minsplit =10, minbucket = 2)
data_train_arbre2=rpart(class~., data_train, method = "class", control = para)

#print(DFApp_arb2)

rpart.plot(data_train_arbre2)

predict2=predict(data_train_arbre2, data_test, type="class")
```


```{r}
# Matrice de confusion

conf2=table(data_test$class,predict2)
print(conf2)

# Taux d'erreur

print(1-sum(diag(conf2))/sum(conf2))

# Taux rappel

print(conf2[2,2]/sum(conf2["normal",]))

# Taux precision

print(conf2[2,2]/sum(conf2[,"normal"]))

```


#################### TEST AVEC METHODE D"ENSEMBLE(PAS ENCORE CV) ################################################




```{r}
install.packages("ipred")
library(ipred)
```

```{r}
data_ensemble=data_train[,]
data_ensemble$class=as.factor(data_train$class)
```



```{r}
set.seed(10)

data_train_ensemble <- bagging(class ~ ., data = data_ensemble, coob = TRUE, nbagg=55)

print(data_train_ensemble)
```


```{r}
predict_ensemble=predict(data_train_ensemble, data_test, type='class')
```



```{r}
# Matrice de confusion

conf3=table(data_test$class,predict_ensemble)
print(conf3)

# Taux d'erreur

print(1-sum(diag(conf3))/sum(conf3))

# Taux rappel

print(conf3[2,2]/sum(conf3["normal",]))

# Taux precision

print(conf3[2,2]/sum(conf3[,"normal"]))

```

```{r}
# Aire de ROC curve

#library(Metrics)
predict_ensemble_proba=predict(data_train_ensemble, data_test, type='prob')
auc(actual = ifelse(data_test$class== "normal", 1, 0), predicted = predict_ensemble_proba[,"normal"]) 

```

#################### TEST AVEC METHODE D"ENSEMBLE(AVEC CV) ################################################


```{r}
# Train avec CV
CV=trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary)
data_ensemble_caret = train(class ~ ., data = data_ensemble, method = "treebag", metric = "ROC", trControl = CV)
print(data_ensemble_caret$results[,"ROC"])
```

```{r}
# Predire sur l'ensemble Test
predict_ensemble_proba_caret=predict(data_ensemble_caret, data_test, type='prob')
auc(actual = ifelse(data_test$class== "normal", 1, 0), predicted = predict_ensemble_proba_caret[,"normal"]) 
```



```{r}
predict_ensemble_caret=predict(data_ensemble_caret, data_test, type='raw')
```



```{r}
#matrice de confusion en utilisant caret
confusionMatrix(data=predict_ensemble_caret,as.factor(data_test$class), positive = 'normal')
```


# SVM
#################################################################################################################
################################################### SVM #########################################################
#################################################################################################################



# Validation croise sur l'ensemble de l'apprentissage et tester sur le test


```{r}
data_svm=data_train[,]
data_svm$class=as.factor(data_train$class)
```




```{r}
svm_fit = svm (class ~. , data =data_svm, type ="C-classification", kernel ="radial" , cross =5)
```


```{r}
predict_svm=predict(svm_fit, data_test, type='raw')
```



```{r}
#matrice de confusion en utilisant caret
confusionMatrix(data=predict_svm,as.factor(data_test$class), positive = 'normal')
```


# Optimisation des hyperparametres



```{r}
#c_seq = c (1 ,10 ,50)
#eps_seq = c (0.05 ,0.1 ,0.5)
#kernel = c("linear", 'polynomial','radial') 
#svm_grid_search = tune ( method = svm , class ~. ,
#data =data_svm , ranges = list ( epsilon = eps_seq , kernel=kernel, cost = c_seq ) )
#print (svm_grid_search)
#plot (svm_grid_search)

```

```{r}
#predict_svm=predict(svm_grid_search$best.model, data_test, type='raw')
```


```{r}
#matrice de confusion en utilisant caret
confusionMatrix(data=predict_svm,as.factor(data_test$class), positive = 'normal')
```



############################################### Gradient Boosting#######################

```{r}
library(gbm)
```


```{r}
data_gb=data_train[,]
data_gb$class=ifelse(data_gb$class=='normal',1,0)
```


```{r}
gb_model=gbm(formula = class~.,distribution = 'bernoulli', cv.folds = 15, data = data_gb, n.trees = 10000)
```



```{r}
# optimiser le nombre d'arbre

ntree_gb <- gbm.perf(gb_model, method = 'cv')
print(ntree_gb)
```

```{r}
data_gb_test=data_test[,]
data_gb_test$class=ifelse(data_gb_test$class=='normal',1,0)
```


```{r}
predict_gb=predict(gb_model,newdata = data_gb_test, n.trees = 9753, type = 'response')
```

```{r}
#matrice de confusion en utilisant caret
library(caret)
prediction_gb=ifelse(predict_gb<0.5,0,1)
confusionMatrix(data=as.factor(prediction_gb),as.factor(data_gb_test$class), positive = '0')
```


```{r}
library(Metrics)
auc(actual = data_gb_test$class, predict_gb)
```
## ROC Curve


```{r}
# liste des predictions avec bagged trees et gradient boosting
preds_list <- list(predict_ensemble_proba[,2], predict_gb)

# liste des valeurs reels
m <- length(preds_list)
actuals_list <- rep(list(data_gb_test$class), m)

# Plot the ROC curves
pred <- prediction(preds_list, actuals_list)
rocs <- performance(pred, "tpr", "fpr")
plot(rocs, col = as.list(1:m), main = "Courbe de ROC sur l'ensemble test")
legend(x = "bottomright", 
       legend = c("Bagged Trees", "GBM"),
       fill = 1:m)

```

# RANDOM FOREST
#################################################################################################################
############################################# RANDOM FOREST #####################################################
#################################################################################################################

```{r}
library(randomForest)
```
```{r}
# preparer le data pour random forest

data_rf=data_train[,]
data_rf$class=as.factor(data_rf$class)
data_rf_x=subset(data_rf,select=-class)
data_rf_y=as.factor(data_rf$class) # il faut transformer en type factor

```



```{r}
# optimisez le hyperparametre mtry:

mtry_search = tuneRF(x=data_rf_x, y = data_rf_y, ntreeTry = 500)
               
mtry_opt <- mtry_search [,"mtry"][which.min(mtry_search [,"OOBError"])]
print(mtry_opt)

```



```{r}
# optimiser les hyperparametres mtry, nodesize, sampsize, ntree

# liste des valeurs des hyperparametres à tester
mtry = seq(4, 19, 2)
nodesize = seq(3, 8, 2)
sampsize = nrow(data_train) * c(0.5, 0.7, 0.8)
#ntree=seq(400,1000,100)

# le dataframe contient toutes les possibilites  
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize) # ntree=ntree)

# vecteur contient des erreurs
oob_err = c()

# recherche des hyperparametres:
for (i in 1:nrow(hyper_grid)) {
  model = randomForest(formula = class ~ ., data = data_rf, mtry = hyper_grid$mtry[i],
                          nodesize = hyper_grid$nodesize[i],
                          sampsize = hyper_grid$sampsize[i])
                          
                       
  oob_err[i] = model$err.rate[nrow(model$err.rate), "OOB"]
}

# identifier les meilleurs hyperparametres
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])

```



```{r}
# train et test avec le meilleur model

model = randomForest(formula = class ~ ., data = data_rf, mtry = 6, nodesize = 3, sampsize = 13225)
predict_rf=predict(model,newdata = data_test, type = 'class')

```



```{r}
confusionMatrix(data=as.factor(predict_rf),as.factor(data_test$class), positive = 'normal')
```

# RESEAUX DE NEURONNE
#################################################################################################################
########################################### RESEAUX DE NEURONNE #################################################
#################################################################################################################

```{r}
install.packages("neuralnet")
install.packages("keras")
```
```{r}
#library
require(neuralnet)
library(keras)
library(mltools)
library(data.table)
library(caret)


#Rename 
names(data_train)[19]<-"class"
names(data_test)[19]<-"class"
#one hot train 
dmy <- dummyVars("~ .",data=data_train)
data_train_onehot<- data.frame(predict(dmy, newdata = data_train))
#Drop colonne normal
data_train_onehot<- data_train_onehot[-20]

#one hot test 
dmy <- dummyVars("~ .",data=data_test)
data_test_onehot<- data.frame(predict(dmy, newdata = data_test))
#Drop colonne normal
data_train_onehot<- data_test_onehot[-20]

```


```{r}
normalize<-function(x){
  return((x-min(x))/max(x)-min(x))
}
maxmindf<-as.data.frame(lapply(data_train_onehot,normalize))
```

```{r}
#fit reseaux de neuronnes 
nn=neuralnet(classanomaly~.,data=maxmindf,hidden=1,act.fct = "logistic",linear.output = FALSE,threshold = 0.01)
plot(nn)
```

## Accuracy


```{r}
temp_test <- data_test_onehot[-19]
head(temp_test)
nn.results <- compute(nn,temp_test)
results <- data.frame(actual = data_test_onehot$classanomaly, prediction = nn.results$net.result)
print(results)
```


## Confusion matrix 

```{r}
roundedresults <- sapply(results, round , digits=0)
roundedresultsdf=data.frame(roundedresults)
attach(roundedresultsdf)
cm<-table(actual,prediction)
print(cm)
#Taux d'erreur
cm[2,1]/sum(cm)
```


















