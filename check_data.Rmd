---
title: "DM1"
author: "Cong Bang Huynh"
date: "12/11/2020"
output: word_document
---


```{r}
#devtools::install_github("clepadellec/ClustersAnalysis")
```

```{r}
library(ClustersAnalysis)
```





```{r}
library(openxlsx)
library(ClustersAnalysis)
```

```{r}
df=read.csv('C:/Users/DELL/Desktop/Master SISE/Github/DataMining/Train_data.csv')
```



```{r}
head(df,10)
```



```{r}
df_not_class=df[,-42]
head(df_not_class)
```

###### variable qualitative #########


```{r}
var_quanti=sapply(df_not_class, function(x) is.factor(x)| is.character(x)|length(unique(x))<50)

```

```{r}
var=var_quanti==FALSE
```



```{r}
df_not_class_quanti=df_not_class[,var]
```


```{r}
head(df_not_class_quanti,10)
```

```{r}
data=cbind(df_not_class_quanti,df$class)
```


```{r}
head(data,10)
```

######################## Test ###########################################################


```{r}
object=multivariate_object(data,22)
```

```{r}
m_test.value(object = object,i=1)
```

#les variables hot/dst_bytes/src_bytes/srv_count caracterise la classe 'normal' le plus mauvais


```{r}
m_test.value(object = object,i=2)
```

# les variables hot/dst_bytes/src_bytes/srv_count caracterise la classe 'normal' le plus mauvais:

```{r}
data_final=data[,-c(2,3,5)]
```

```{r}
object=multivariate_object(data_final,19)
```



# Rapport de correlation

```{r}
### R^2

m_R2_multivariate(object, rescale = TRUE)


```





```{r}
colnames(data_final)
```


# fisher test


```{r}
u_object=Univariate_object(data_final,19)
```



```{r}
u_fisher_test_all(u_object)
```






# Le nombre des valeurs differentes pour chaque colonne

```{r}
for (i in 1:18){
  a=length(unique(data_final[,i]))
  print(paste(colnames(data_final[i]), a))
}
```

##SÃ©parer en train-test (0.75-0.25)

```{r}
colnames(data_final)[19]='class'
```


```{r}
n=nrow(data_final)
ind_test=sample(1:n, n*0.25, replace = FALSE, prob = NULL)
data_train=data_final[-ind_test,]
data_test=data_final[ind_test,]
```








###################ACP########################################################################################




```{r}
#ACP + clustering sur l'apprentissage (data_train)
m_data_train=multivariate_object(data_train,19)
m_kmean_clustering_plot(m_data_train, interact = FALSE, rescale = TRUE)
```



```{r}
#ACP + clustering sur le test (data_test)
m_data_test=multivariate_object(data_test,19)
m_kmean_clustering_plot(m_data_train, interact = FALSE)
```



```{r}
#ACP + clustering sur le test (data_test)
m_data_total=multivariate_object(data_final,19)
m_kmean_clustering_plot(m_data_total, interact = FALSE, i=1,j=2)

```
















#################### TEST AVEC ARBRE DE DECISION (PAS ENCORE CV) ################################################
#TEST AVEC ARBRE DE DECISION



```{r}
head(data_train)
```





##Lancer Arbre de decision

```{r}
library(rpart)
data_train_arbre=rpart(class~.,data=data_train, method = "class")
plot(data_train_arbre)
text(data_train_arbre)

```

```{r}
library(rpart.plot)

rpart.plot(data_train_arbre)
```

## Predire avec arbre de decision



```{r}
predict=predict(data_train_arbre, data_test,"class")
```


## Calculer les metriques

```{r}
# Matrice de confusion

conf1=table(data_test$class,predict)
print(conf1)

# Taux d'erreur

print(1-sum(diag(conf1))/sum(conf1))

# Taux rappel

print(conf1[2,2]/sum(conf1["normal",]))

# Taux precision

print(conf1[2,2]/sum(conf1[,"normal"]))
```


## tuning les hyperparametres

```{r}
para=rpart.control(minsplit =10, minbucket = 2)
data_train_arbre2=rpart(class~., data_train, method = "class", control = para)

#print(DFApp_arb2)

rpart.plot(data_train_arbre2)

predict2=predict(data_train_arbre2, data_test, type="class")
```


```{r}
# Matrice de confusion

conf2=table(data_test$class,predict2)
print(conf2)

# Taux d'erreur

print(1-sum(diag(conf2))/sum(conf2))

# Taux rappel

print(conf2[2,2]/sum(conf2["normal",]))

# Taux precision

print(conf2[2,2]/sum(conf2[,"normal"]))

```


#################### TEST AVEC METHODE D"ENSEMBLE(PAS ENCORE CV) ################################################




```{r}
library(ipred)
```

```{r}
data_ensemble=data_train[,]
data_ensemble$class=as.factor(data_train$class)
```



```{r}
set.seed(10)

data_train_ensemble <- bagging(class ~ ., data = data_ensemble, coob = TRUE, nbagg=55)

print(data_train_ensemble)
```


```{r}
predict_ensemble=predict(data_train_ensemble, data_test, type='class')
```



```{r}
# Matrice de confusion

conf3=table(data_test$class,predict_ensemble)
print(conf3)

# Taux d'erreur

print(1-sum(diag(conf3))/sum(conf3))

# Taux rappel

print(conf3[2,2]/sum(conf3["normal",]))

# Taux precision

print(conf3[2,2]/sum(conf3[,"normal"]))

```

```{r}
# Aire de ROC curve

#library(Metrics)
predict_ensemble_proba=predict(data_train_ensemble, data_test, type='prob')
auc(actual = ifelse(data_test$class== "normal", 1, 0), predicted = predict_ensemble_proba[,"normal"]) 

```

#################### TEST AVEC METHODE D"ENSEMBLE(AVEC CV) ################################################


```{r}
library(caret)
```


```{r}
# Train avec CV
CV=trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary)
data_ensemble_caret = train(class ~ ., data = data_ensemble, method = "treebag", metric = "ROC", trControl = CV)
print(data_ensemble_caret$results[,"ROC"])
```

```{r}
# Predire sur l'ensemble Test
predict_ensemble_proba_caret=predict(data_ensemble_caret, data_test, type='prob')
auc(actual = ifelse(data_test$class== "normal", 1, 0), predicted = predict_ensemble_proba_caret[,"normal"]) 
```



```{r}
predict_ensemble_caret=predict(data_ensemble_caret, data_test, type='raw')
```



```{r}
# Matrice de confusion

conf4=table(data_test$class,predict_ensemble_caret)
print(conf4)

# Taux d'erreur

print(1-sum(diag(conf4))/sum(conf4))

# Taux rappel

print(conf4[2,2]/sum(conf4["normal",]))

# Taux precision

print(conf4[2,2]/sum(conf4[,"normal"]))

```




###################################SVM####################################################################


```{r}
library(e1071)
```

# Validation croise sur l'ensemble de l'apprentissage et tester sur le test


```{r}
data_svm=data_train[,]
data_svm$class=as.factor(data_train$class)
```




```{r}
svm_fit = svm (class ~. , data =data_svm, type ="C-classification", kernel ="radial" , cross =5)
```


```{r}
predict_svm=predict(svm_fit, data_test, type='raw')
```



```{r}
# Matrice de confusion

conf4=table(data_test$class,predict_svm)
print(conf4)

# Taux d'erreur

print(1-sum(diag(conf4))/sum(conf4))

# Taux rappel 

print(conf4[2,2]/sum(conf4["normal",]))

# Taux precision

print(conf4[2,2]/sum(conf4[,"normal"]))

```


# Optimisation des hyperparametres



```{r}
c_seq = c (1 ,10 ,50)
eps_seq = c (0.05 ,0.1 ,0.5)
kernel = c("linear", 'polynomial','radial') 
svm_grid_search = tune ( method = svm , class ~. ,
data =data_svm , ranges = list ( epsilon = eps_seq , kernel=kernel, cost = c_seq ) )
print (svm_grid_search)
#plot (svm_grid_search)

```

```{r}
predict_svm=predict(svm_grid_search$best.model, data_test, type='raw')
```



```{r}
# Matrice de confusion

conf4=table(data_test$class,predict_svm)
print(conf4)

# Taux d'erreur

print(1-sum(diag(conf4))/sum(conf4))

# Taux rappel 

print(conf4[2,2]/sum(conf4["normal",]))

# Taux precision

print(conf4[2,2]/sum(conf4[,"normal"]))

```




































