---
title: "Partie 1"
author: "Pauline Lainé"
date: "18/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Partie 1 

## Lecture et description des données
#Question 2
```{r}
#Chargement des données
#setwd("C:/Users/DELL/Desktop/Master SISE/Github/Ahpine/DataMining")
D <- read.table("breast-cancer-wisconsin.data", sep = ",")

```


# Question 3
```{r}
class(D)
str(D)
head(D)
summary(D)
#C'est un jeu de données de type dataframe avec 699 observations et 11 variables
```

## Séparation des données en "train" et "test"

# Question 4
```{r}
#Modifider les "?" en NA
D$V7[D$V7=="?"] <- NA
#Vérifier si les lignes sont complète ou non 
ok <- complete.cases(D)
#Nombre de ligne avec valeurs manquantes (16)
sum(!ok)
#Lignes avec valeurs manquantes
D[!ok,]
```

#Question 5
Pour avoir que des données complètes, on choisit de supprimé les individus avec des données manquantes 
```{r}
D <- D[ok,]
```

#Question 6 
```{r}
#Variables explicatives
X <- D[,c(2:10)]
#Variable cible
y <- D[,11]
```

#Question 7
```{r}
#Recodage bégnime
y[y==2] <- 0
#Recodage maligne
y[y==4] <- 1
```

#Question 8
```{R}
#Indice des observations benignes
benin <- which(y==0)
#Indice des observations malignes
malin <- which(y==1)
```

#Question 9 
```{R}
#Indice des ensemble d'entrainement et de test
# 200 premières observations benins
train_set <- benin[0:200]
#maligne et une partie des benins
test_set <- union(setdiff(benin,train_set),malin)
```



## 4 ONE CLASS SVM 
#Question 10 
```{r}
#Chargement des librairies 
library(e1071)
library(rpart)
```


#Question 11
```{r}
#changer le type du V7
X$V7=as.numeric(D$V7)

oc_svm_fit <- svm(as.matrix(X[train_set,]),y=NULL,kernel = "radial", type ="one-classification" , gamma = 1/2)
summary(oc_svm_fit)
```
#Question 12
```{r}
#Prédiction des scores 
oc_svm_pred_test  <- predict(oc_svm_fit, X[test_set,],decision.values = TRUE)
```

#Question 13 
```{r}
#récupere l'attribut decision.values de la prédiction et la convertie en numérique
attr(oc_svm_pred_test ,"decision.values")
oc_svm_score_test=-as.numeric(attr(oc_svm_pred_test ,"decision.values"))
plot(oc_svm_score_test)

```

##COUBRE ROC

#Question 14
```{r}
#Chargement de la librairie
#install.packages("ROCR")
library(ROCR)
```

#Question 15
```{r}
pred_oc_svm=prediction(oc_svm_score_test, y[test_set])
oc_svm_roc=performance(pred_oc_svm,measure="tpr",x.measure = "fpr")
plot(oc_svm_roc)
```
AUC est plutot high 

#Question 16

Modele predicte plutot bien.


```{r}
#calculer auc
auc_ROCR <- performance(pred_oc_svm, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]
print(auc_ROCR)
# AUC = 0.99, l'AUC est élevé le modèle est donc performant
```




## PCA kernel

```{r}
#changer le type du V7
#X$V7=as.numeric(D$V7)
```


#Question 17

```{r}
# chargement la librairie kernlab
#install.packages("kernlab")
library (kernlab)
```


```{r}
#instancier le Radial Basis kernel function "Gaussian" avec sigma=1/8
kernel = rbfdot(sigma=1/8)

# calculer la matrice à noyau avec le noyau radial pour l'ensemble d'apprentissage
Ktrain = kernelMatrix(kernel =kernel,x=as.matrix(X[train_set,]))
```


#Question 18

```{r}
# calculer deuxieme terme de la formule (1)
k2 = apply(Ktrain,1,sum)
# calculer troisieme terme de la formule (1)
k3 = apply(Ktrain,2,sum)
# calculer quatrieme terme de la formule (1)
k4 = sum(Ktrain)
# nombre de ligne du Ktrain
n=nrow(Ktrain)
# construire une matrice de n lignes et n colonnes
KtrainCent = matrix(0,ncol=n,nrow=n)

#formule (1)
for(i in 1:n){
  for (j in 1:n){
    #calcul le coefficient (K'(i,j)) de la matrice K' qui est la transformation de la matrice à noyau K
    KtrainCent[i,j]= Ktrain[i,j]-1/n*k2[i]-1/n*k3[j]+1/n^2*k4
    }
  }
```

#Question )=)àç_àpo^lmjiuçàjà

```{r}
# la décomposition spectrale de la matrice KtrainCent
eigen_KtrainCent=eigen(KtrainCent)
```

#Question 20

```{r}
# calculer les alpha_m
s=80
A = eigen_KtrainCent$vectors[,1:s]%*% diag(1/sqrt(eigen_KtrainCent$values[1:s]))

```

#Question 21

```{r}
# calculer la matrice à noyau avec le noyau radial pour tous les individus
K = kernelMatrix(kernel,as.matrix(X))
```

#Question 22

```{r}
# calculer le premier  n  terme de la formule (4)
p1=as.numeric(diag(K))
# calculer le deuxieme terme de la formule (4)
p2=as.numeric(-2/n*apply(K[,train_set],1,sum))
# calculer le troisieme terme de la formule (4)
p3=as.numeric(1/(n^2)*sum(K[train_set,train_set]))
```

#Question 23

```{r}
#Formule (4)
ps=p1[test_set]+p2[test_set]+p3
```

#Question 24

```{r}
#Termes de la formule (5)
f1=K[,train_set]%*% A
f2=as.numeric(-1/n*(t(A)%*%apply(K[train_set,train_set],1,sum)))
f3=as.matrix(-1/n*apply(K[,train_set],1,sum))%*% t(as.matrix(apply(A,2,sum)))
f4=1/(n^2)*sum(K[train_set,train_set])*apply(A,2,sum)
```

# Question 25


```{r}
#Formule (5)
f2bis=matrix(rep(f2,683), nrow=683,ncol=80,byrow=T)
f4bis=matrix(rep(f4,683), nrow=683,ncol=80,byrow=T)
fl=f1[test_set,]+f2bis[test_set,]+f3[test_set,]+f4bis[test_set,]
```

#Question 26

```{r}
#Formule (6)
fl_somme=apply(fl*fl,1,sum)
#Score de la formule (3)
kpca_score_test=ps-fl_somme
```

```{r}
kpca_score_test[1:20]
```

#Question 27

```{r}
library(ROCR)
```


```{r}
#Courbe ROC du SVM et du kernel PCA pour comparer
pred_oc_kpca = prediction(kpca_score_test,y[test_set])
oc_kpca_roc = performance(pred_oc_kpca, measure = "tpr", x.measure= "fpr")
plot(oc_svm_roc)
plot(oc_kpca_roc, add=TRUE, col=2)

```


```{r}
#calculer auc
auc_ROCR <- performance(pred_oc_kpca, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]
print(auc_ROCR)
```

D'après la courbe et l'AUC le modèle Kernel PCA est aussi performant que le SMV. Néamoins si on compare les deux AUC, celui du kernel PCA est légèrement plus élevé. 
AUC SVM = 0.9923863
AUC Kernel PCA = 0.99627