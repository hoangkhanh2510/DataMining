---
title: "Partie 1"
author: "Pauline Lainé"
date: "18/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Partie 1 

## Lecture et description des données
#Question 2
```{r}
#Chargement des données
setwd("C:/Users/DELL/Desktop/Master SISE/Github/Ahpine/DataMining")#D:/OneDrive/Documents/COURS/M2 SISE/Machine learning ahpine/Projet")
D <- read.table("breast-cancer-wisconsin.data", sep = ",")

```


# Question 3
```{r}
class(D)
str(D)
head(D)
summary(D)
```

## Séparation des données en "train" et "test"

# Question 4
```{r}
#Modifider les "?" en NA
D$V7[D$V7=="?"] <- NA
#Vérifier si les lignes sont complète ou non 
ok <- complete.cases(D)
#Nombre de ligne avec valeurs manquantes
sum(!ok)
#Lignes avec valeurs manquantes
D[!ok,]
```

#Question 5
Pour avoir que des données complètes, on choisit de supprimé les individus avec des données manquantes 
```{r}
D <- D[ok,]
```

#Question 6 
```{r}
#Variables explicatives
X <- D[,c(2:10)]
#Variable cible
y <- D[,11]
```

#Question 7
```{r}
#Recodage bégnime
y[y==2] <- 0
#Recodage maligne
y[y==4] <- 1
```

#Question 8
```{R}
#Indice des benigne et maligne
benin <- which(y==0)
malin <- which(y==1)
```

#Question 9 
```{R}
#Indice des ensemble d'entrainement et de test
# 200 premières observations benins
train_set <- benin[0:200]
#maligne et une partie des benins
test_set <- union(setdiff(benin,train_set),malin)
```



## 4 ONE CLASS SVM 
#Question 10 
```{r}
#Chargez 
library(e1071)
library(rpart)
```





#Question 11
```{r}
#changer le type du V7
X$V7=as.numeric(D$V7)

oc_svm_fit <- svm(as.matrix(X[train_set,]),y=NULL,kernel = "radial", type ="one-classification" , gamma = 1/2)
summary(oc_svm_fit)
```
#Question 12
```{r}
oc_svm_pred_test  <- predict(oc_svm_fit, X[test_set,],decision.values = TRUE)
```

#Question 13 
```{r}
attr(oc_svm_pred_test ,"decision.values")
oc_svm_score_test=-as.numeric(attr(oc_svm_pred_test ,"decision.values"))
plot(oc_svm_score_test)
```
#COUBRE ROC

#Question 14
```{r}
#install.packages("ROCR")
library(ROCR)
```

#Question 15
```{r}
pred_oc_svm=prediction(oc_svm_score_test, y[test_set])
oc_svm_roc=performance(pred_oc_svm,measure="tpr",x.measure = "fpr")
plot(oc_svm_roc)
```
AUC est plutot high 

#Question 16

Modele predicte plutot bien.


```{r}
#calculer auc
auc_ROCR <- performance(pred_oc_svm, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]
print(auc_ROCR)
```




## PCA kernel

```{r}
#changer le type du V7
X$V7=as.numeric(D$V7)
```


Q17

```{r}
# chargement la librairie kernlab
library (kernlab)
```


```{r}
#instancier le Radial Basis kernel function "Gaussian" avec sigma=1/8
kernel = rbfdot(sigma=1/8)

# calculer la matrice à noyau avec le noyau radial pour l'ensemble d'apprentissage
Ktrain = kernelMatrix(kernel =kernel,x=as.matrix(X[train_set,]))
```


Q18

```{r}
# calculer deuxieme terme de la somme dans la formule (1)
k2 = apply(Ktrain,1,sum)
# calculer troisieme terme de la somme dans la formule (1)
k3 = apply(Ktrain,2,sum)
# calculer quatrieme terme de la somme dans la formule (1)
k4 = sum(Ktrain)
# nombre de ligne du Ktrain
n=nrow(Ktrain)
# construire une matrice de n lignes et n colonnes
KtrainCent = matrix(0,ncol=n,nrow=n)

for(i in 1:n){
  for (j in 1:n){
    #calcul le coefficient (K'(i,j)) de la matrice K' qui est la transformation de la matrice à noyau K
    KtrainCent[i,j]= Ktrain[i,j]-1/n*k2[i]-1/n*k3[j]+1/n^2*k4
    }
  }
```

Q19


```{r}
# la décomposition spectrale de la matrice KtrainCent
eigen_KtrainCent=eigen(KtrainCent)
```


Q20



```{r}
# calculer les alpha_m
s=80
A = eigen_KtrainCent$vectors[,1:s]%*% diag(1/sqrt(eigen_KtrainCent$values[1:s]))

```


Q21

```{r}
# calculer la matrice à noyau avec le noyau radial pour tous les individus
K = kernelMatrix(kernel,as.matrix(X))
```


Q22



```{r}
# calculer le premier terme de la somme dans la formule (4)
p1=as.numeric(diag(K))
# calculer le deuxieme terme de la somme dans la formule (4)
p2=as.numeric(-2/n*apply(K[,train_set],1,sum))
# calculer le troisieme terme de la somme dans la formule (4)
p3=as.numeric(1/(n^2)*sum(K[train_set,train_set]))

```


Q23



```{r}
ps=p1[test_set]+p2[test_set]+p3
```



Q24

```{r}
f1=K[,train_set]%*% A
f2=as.numeric(-1/n*(t(A)%*%apply(K[train_set,train_set],1,sum)))
f3=as.matrix(-1/n*apply(K[,train_set],1,sum))%*% t(as.matrix(apply(A,2,sum)))
f4=1/(n^2)*sum(K[train_set,train_set])*apply(A,2,sum)
```


Q25


```{r}
f2bis=matrix(rep(f2,683), nrow=683,ncol=80,byrow=T)
f4bis=matrix(rep(f4,683), nrow=683,ncol=80,byrow=T)
fl=f1[test_set,]+f2bis[test_set,]+f3[test_set,]+f4bis[test_set,]
```



Q26

```{r}
fl_somme=apply(fl*fl,1,sum)
kpca_score_test=ps-fl_somme
```




```{r}
kpca_score_test[1:20]
```

Q27

```{r}
library(ROCR)
```


```{r}

pred_oc_kpca = prediction(kpca_score_test,y[test_set])
oc_kpca_roc = performance(pred_oc_kpca, measure = "tpr", x.measure= "fpr")
plot(oc_svm_roc)
plot(oc_kpca_roc, add=TRUE, col=2)

```








```{r}
#calculer auc
auc_ROCR <- performance(pred_oc_kpca, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]
print(auc_ROCR)
```



















